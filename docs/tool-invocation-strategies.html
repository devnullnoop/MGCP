<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tool Invocation Strategies</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #0f0f23 0%, #1a1a3e 100%);
            min-height: 100vh;
            color: #e0e0e0;
            padding: 2rem;
            line-height: 1.6;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        h1 { text-align: center; color: #fff; font-size: 2rem; margin-bottom: 0.5rem; }
        h2 { color: #4fc3f7; margin: 2rem 0 1rem; border-bottom: 2px solid #4fc3f7; padding-bottom: 0.5rem; }
        h3 { color: #81c784; margin: 1.5rem 0 0.75rem; }
        .subtitle { text-align: center; color: #888; margin-bottom: 2rem; }
        .section {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            padding: 2rem;
            margin-bottom: 2rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 1.5rem;
            margin: 1.5rem 0;
        }
        .card {
            background: rgba(255, 255, 255, 0.03);
            border-radius: 8px;
            padding: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.08);
        }
        .card h4 { color: #ffb74d; margin-bottom: 0.75rem; }
        .card.recommended { border: 2px solid #4caf50; }
        .card.experimental { border: 2px solid #ff9800; }
        .card.risky { border: 2px solid #f44336; }
        .badge {
            display: inline-block;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
            font-size: 0.75rem;
            margin-left: 0.5rem;
        }
        .badge.green { background: #2e7d32; }
        .badge.orange { background: #f57c00; }
        .badge.red { background: #c62828; }
        .badge.blue { background: #1565c0; }
        .mermaid { display: flex; justify-content: center; margin: 1.5rem 0; }
        table { width: 100%; border-collapse: collapse; margin: 1rem 0; }
        th, td { padding: 0.75rem; text-align: left; border-bottom: 1px solid rgba(255,255,255,0.1); }
        th { background: rgba(79, 195, 247, 0.2); color: #4fc3f7; }
        code {
            background: rgba(0,0,0,0.3);
            padding: 0.2rem 0.4rem;
            border-radius: 4px;
            font-family: 'Fira Code', monospace;
            font-size: 0.9rem;
        }
        pre {
            background: rgba(0,0,0,0.4);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1rem 0;
        }
        ul, ol { margin: 1rem 0 1rem 1.5rem; }
        li { margin: 0.5rem 0; }
        .pros { color: #81c784; }
        .cons { color: #ef5350; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Ensuring Tool Invocation</h1>
        <p class="subtitle">Strategies to maximize lesson retrieval reliability</p>

        <section class="section">
            <h2>The Core Problem</h2>
            <div class="mermaid">
flowchart LR
    User["User Request"] --> LLM["LLM Decision Point"]
    LLM -->|"Decides to query"| Tool["query_lessons()"]
    LLM -->|"Decides NOT to query"| Direct["Answer from training"]
    Tool --> Good["âœ“ Lesson applied"]
    Direct --> Bad["âœ— Lesson missed"]

    style LLM fill:#ff9800,stroke:#f57c00,color:#000
    style Bad fill:#c62828,stroke:#b71c1c,color:#fff
    style Good fill:#2e7d32,stroke:#1b5e20,color:#fff
            </div>
            <p>The LLM is the decision-maker. We can only <em>influence</em>, not <em>control</em>. Here are strategies ordered from most to least reliable:</p>
        </section>

        <section class="section">
            <h2>Strategy 1: Bypass the Decision Entirely</h2>
            <p><strong>Philosophy:</strong> Don't rely on the LLM to query. Inject lessons proactively.</p>

            <div class="grid">
                <div class="card recommended">
                    <h4>1A. Bootstrap Lessons <span class="badge green">Recommended</span></h4>
                    <p>Auto-load high-priority lessons at session start, before any user interaction.</p>
                    <pre><code># In MCP server initialization
@server.list_resources()
async def list_resources():
    return [
        Resource(
            uri="lessons://bootstrap",
            name="Global Lessons",
            description="Always-loaded lessons"
        )
    ]</code></pre>
                    <p class="pros">âœ“ 100% reliable for critical lessons</p>
                    <p class="pros">âœ“ Uses MCP Resources (auto-loaded) not Tools</p>
                    <p class="cons">âœ— Consumes tokens even when not needed</p>
                    <p class="cons">âœ— Limited to ~10-20 lessons before token bloat</p>
                </div>

                <div class="card recommended">
                    <h4>1B. Project Context Detection <span class="badge green">Recommended</span></h4>
                    <p>Detect project type and auto-inject relevant category.</p>
                    <pre><code># Detect from files in workspace
if "Cargo.toml" in workspace:
    auto_load("rust-lessons")
elif "pyproject.toml" in workspace:
    auto_load("python-lessons")</code></pre>
                    <p class="pros">âœ“ Contextually relevant</p>
                    <p class="pros">âœ“ No LLM decision needed</p>
                    <p class="cons">âœ— Requires project detection logic</p>
                    <p class="cons">âœ— May miss cross-domain lessons</p>
                </div>

                <div class="card experimental">
                    <h4>1C. Claude Code Hooks <span class="badge orange">Experimental</span></h4>
                    <p>Use Claude Code's hook system to inject lessons on specific events.</p>
                    <pre><code># .claude/hooks/pre-task.sh
# Triggered before each task
claude-mcp query-lessons "$TASK_DESCRIPTION"</code></pre>
                    <p class="pros">âœ“ Task-aware injection</p>
                    <p class="pros">âœ“ Works at shell level</p>
                    <p class="cons">âœ— Hook system may change</p>
                    <p class="cons">âœ— Adds latency to every task</p>
                </div>
            </div>
        </section>

        <section class="section">
            <h2>Strategy 2: Maximize Invocation Likelihood</h2>
            <p><strong>Philosophy:</strong> Make it as easy as possible for the LLM to recognize when to call tools.</p>

            <div class="grid">
                <div class="card recommended">
                    <h4>2A. Exceptional Tool Descriptions <span class="badge green">Critical</span></h4>
                    <p>Tool descriptions are the #1 factor in invocation. Invest heavily here.</p>
                    <pre><code>{
  "name": "query_lessons",
  "description": "ALWAYS call this tool FIRST when starting a new coding task. Retrieves lessons learned from past mistakes and best practices. Call with a brief description of what you're about to do. Examples: 'implementing auth', 'writing tests', 'optimizing performance'. Returns 3-5 relevant lessons to apply.",
  "inputSchema": {
    "type": "object",
    "properties": {
      "task": {
        "type": "string",
        "description": "Brief description of current task (2-10 words)"
      }
    },
    "required": ["task"]
  }
}</code></pre>
                    <p>Key elements:</p>
                    <ul>
                        <li><strong>ALWAYS/FIRST</strong> - imperative language</li>
                        <li><strong>When to call</strong> - explicit trigger</li>
                        <li><strong>Examples</strong> - reduces ambiguity</li>
                        <li><strong>What you get</strong> - value proposition</li>
                    </ul>
                </div>

                <div class="card recommended">
                    <h4>2B. Multiple Specialized Tools <span class="badge green">Recommended</span></h4>
                    <p>One general tool is harder to match than specific ones.</p>
                    <table>
                        <tr>
                            <th>Instead of</th>
                            <th>Use</th>
                        </tr>
                        <tr>
                            <td><code>query_lessons(task)</code></td>
                            <td>
                                <code>get_testing_lessons()</code><br>
                                <code>get_api_lessons()</code><br>
                                <code>get_error_handling_lessons()</code><br>
                                <code>get_performance_lessons()</code>
                            </td>
                        </tr>
                    </table>
                    <p class="pros">âœ“ Easier intent matching</p>
                    <p class="pros">âœ“ More specific triggers</p>
                    <p class="cons">âœ— More tools to maintain</p>
                    <p class="cons">âœ— May still miss edge cases</p>
                </div>

                <div class="card experimental">
                    <h4>2C. System Prompt Reinforcement <span class="badge orange">Experimental</span></h4>
                    <p>Add to CLAUDE.md or system prompt:</p>
                    <pre><code>## Lesson Memory System

Before starting any coding task, ALWAYS query the lesson memory:
1. Call `query_lessons` with your task description
2. Review returned lessons
3. Apply relevant lessons to your approach

This prevents repeating past mistakes.</code></pre>
                    <p class="pros">âœ“ Direct instruction to model</p>
                    <p class="cons">âœ— May be ignored in long conversations</p>
                    <p class="cons">âœ— Competes with other instructions</p>
                </div>
            </div>
        </section>

        <section class="section">
            <h2>Strategy 3: Detect and Recover</h2>
            <p><strong>Philosophy:</strong> If the LLM doesn't query, catch it afterward and correct.</p>

            <div class="grid">
                <div class="card experimental">
                    <h4>3A. Post-Response Hook <span class="badge orange">Complex</span></h4>
                    <p>Analyze LLM response, detect if lessons were missed, suggest retrieval.</p>
                    <div class="mermaid">
sequenceDiagram
    User->>LLM: "Implement auth"
    LLM->>User: [Response without querying lessons]
    Hook->>Analyzer: Check if lessons exist for "auth"
    Analyzer-->>Hook: Found: auth-lessons, jwt-lessons
    Hook->>User: "ðŸ’¡ Relevant lessons available. Query?"
                    </div>
                    <p class="pros">âœ“ Catches missed opportunities</p>
                    <p class="cons">âœ— After-the-fact (damage may be done)</p>
                    <p class="cons">âœ— Requires response analysis</p>
                </div>

                <div class="card recommended">
                    <h4>3B. Manual Trigger Command <span class="badge blue">Simple</span></h4>
                    <p>Let users explicitly request lessons when they notice omission.</p>
                    <pre><code># User can type:
/lessons auth

# Or in conversation:
"What lessons do we have about authentication?"</code></pre>
                    <p class="pros">âœ“ User control</p>
                    <p class="pros">âœ“ Simple to implement</p>
                    <p class="cons">âœ— Relies on user awareness</p>
                    <p class="cons">âœ— Defeats automation goal</p>
                </div>

                <div class="card experimental">
                    <h4>3C. Periodic Reminder <span class="badge orange">Intrusive</span></h4>
                    <p>In long conversations, periodically remind the LLM about lessons.</p>
                    <pre><code># Every N messages, inject:
"[System: Remember to query lesson memory for relevant guidance]"</code></pre>
                    <p class="pros">âœ“ Handles context drift</p>
                    <p class="cons">âœ— Annoying to users</p>
                    <p class="cons">âœ— Consumes tokens</p>
                </div>
            </div>
        </section>

        <section class="section">
            <h2>Strategy 4: Hybrid Architecture</h2>
            <p><strong>Philosophy:</strong> Combine multiple strategies for defense in depth.</p>

            <div class="mermaid">
flowchart TB
    subgraph Always["Always Loaded (Resources)"]
        Global["Global Lessons<br/>(10-15 critical)"]
        Project["Project-Specific<br/>(detected from workspace)"]
    end

    subgraph OnDemand["On-Demand (Tools)"]
        Query["query_lessons()<br/>(semantic search)"]
        Category["get_*_lessons()<br/>(category browse)"]
        Spider["spider_lessons()<br/>(graph traversal)"]
    end

    subgraph Fallback["Fallback"]
        Manual["User: /lessons"]
        Hook["Post-response hook"]
    end

    User["User Task"] --> Always
    Always --> LLM["LLM Processing"]
    LLM -->|"Decides to query"| OnDemand
    OnDemand --> LLM
    LLM -->|"Misses query"| Fallback
    Fallback -->|"Recovery"| LLM
    LLM --> Response["Response"]

    style Always fill:#2e7d32,stroke:#1b5e20,color:#fff
    style OnDemand fill:#1565c0,stroke:#0d47a1,color:#fff
    style Fallback fill:#ff9800,stroke:#f57c00,color:#000
            </div>

            <h3>Recommended Hybrid Setup</h3>
            <table>
                <thead>
                    <tr>
                        <th>Layer</th>
                        <th>Mechanism</th>
                        <th>Coverage</th>
                        <th>Reliability</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Layer 1</strong></td>
                        <td>Bootstrap global lessons (MCP Resources)</td>
                        <td>Critical lessons</td>
                        <td>100%</td>
                    </tr>
                    <tr>
                        <td><strong>Layer 2</strong></td>
                        <td>Project detection auto-load</td>
                        <td>Language/framework specific</td>
                        <td>~95%</td>
                    </tr>
                    <tr>
                        <td><strong>Layer 3</strong></td>
                        <td>Excellent tool descriptions</td>
                        <td>Task-specific deep knowledge</td>
                        <td>~60-70%</td>
                    </tr>
                    <tr>
                        <td><strong>Layer 4</strong></td>
                        <td>Manual /lessons command</td>
                        <td>User-directed recovery</td>
                        <td>User-dependent</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section class="section">
            <h2>Implementation Priority</h2>

            <h3>Phase 1: Foundation</h3>
            <ol>
                <li><strong>Exceptional tool descriptions</strong> - This is free and high-impact</li>
                <li><strong>Bootstrap lessons via MCP Resources</strong> - Guarantee critical lessons load</li>
                <li><strong>Manual /lessons command</strong> - Simple fallback</li>
            </ol>

            <h3>Phase 2: Enhancement</h3>
            <ol start="4">
                <li><strong>Project context detection</strong> - Auto-load relevant categories</li>
                <li><strong>Multiple specialized tools</strong> - Improve intent matching</li>
                <li><strong>CLAUDE.md reinforcement</strong> - System prompt guidance</li>
            </ol>

            <h3>Phase 3: Advanced (If Needed)</h3>
            <ol start="7">
                <li><strong>Post-response analysis hooks</strong> - Detect missed opportunities</li>
                <li><strong>Invocation analytics</strong> - Track and optimize</li>
            </ol>
        </section>

        <section class="section">
            <h2>Key Insight</h2>
            <div style="background: rgba(79, 195, 247, 0.1); border-left: 4px solid #4fc3f7; padding: 1.5rem; border-radius: 0 8px 8px 0;">
                <p style="font-size: 1.1rem; margin: 0;">
                    <strong>Don't try to solve 100% invocation.</strong> Accept that query-based retrieval will be ~60-70% reliable.
                    Use the hybrid approach: <strong>bootstrap critical lessons</strong> (100% reliable),
                    <strong>auto-load project context</strong> (~95% reliable), and let query-based retrieval handle the long tail.
                </p>
            </div>
        </section>
    </div>

    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'dark',
            flowchart: { useMaxWidth: true, htmlLabels: true, curve: 'basis' }
        });
    </script>
</body>
</html>